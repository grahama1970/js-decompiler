# JS-Decompiler: JavaScript Decompilation Pipeline

**Note**: This is an experimental tool for analyzing minified JavaScript files, such as `input/cli.js`, for educational purposes only. Ensure you have permission to analyze the input file. âš ï¸

## ğŸš€ Purpose

This script deconstructs a minified JavaScript file into modular components, creating a pseudo-sourcemap, dependency graph, and AI-generated analysis. It processes the input through a pipeline:

1. **Prettier**: Formats code for readability.
2. **Webcrack**: Deobfuscates variable names.
3. **Tree-sitter**: Splits code into modular files (functions, classes, etc.).
4. **Directory Analysis**: Creates summaries for each component type.
5. **Category Analysis**: Provides multi-faceted analysis using Vertex AI or Ollama.

The goal is to reverse-engineer minified JavaScript, making it easier to understand its structure and functionality.

## ğŸ¯ Why

To learn how to break down a minified JavaScript file into manageable parts, approximate a source map, and leverage AI to analyze code, enhancing reverse-engineering skills.

## ğŸ“‹ Prerequisites

- **Node.js** v22.15.0 or later (`node --version` to check).
- One of the following LLM providers:
  - **Google Vertex AI** service account JSON key, placed in `config/vertex_ai_service_account.json`.
  - **Ollama** local instance running at `http://localhost:11435` (default port) with your preferred model.
- **Git** (optional, for version control).

## ğŸ› ï¸ Installation

1. Clone this repository or copy the project files.
2. Navigate to the project root:
   ```bash
   cd project-root
   ```
3. Initialize a Node.js project (if not already done):
   ```bash
   npm init -y
   ```
4. Install dependencies using `package.json`:
   ```bash
   npm install
   ```
   This installs `prettier`, `webcrack`, `tree-sitter`, `@langchain/google-vertexai`, `ollama`, `dotenv`, `yargs`, and `eslint`.
5. Configure your preferred LLM provider:
   - For **Vertex AI**: Place your service account JSON key in `config/vertex_ai_service_account.json`.
   - For **Ollama**: Ensure your Ollama server is running (check with `docker ps` if using Docker).
6. Create a `config/.env` file:
   ```env
   # For Vertex AI
   VERTEX_AI_CREDENTIALS_PATH=config/vertex_ai_service_account.json
   
   # For Ollama
   LLM_PROVIDER=ollama
   OLLAMA_HOST=http://localhost:11435
   OLLAMA_MODEL=qwen3:30b-a3b-q8_0
   ```
7. Ensure `.gitignore` includes `config/vertex_ai_service_account.json`, `.env`, `node_modules/`, and `output/` to protect sensitive data.

## ğŸ“‚ Project Structure

```
project-root/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ deconstruct_pipeline.js   # Main script
â”‚   â””â”€â”€ utils/                   # Utility modules
â”‚       â”œâ”€â”€ helpers.js           # Helper functions
â”‚       â”œâ”€â”€ rolling_window_summarizer.js  # Text summarization 
â”‚       â””â”€â”€ cleanup_outputs.js   # Output management
â”œâ”€â”€ config/                      # Configuration files
â”‚   â”œâ”€â”€ .env                     # Environment variables
â”‚   â””â”€â”€ vertex_ai_service_account.json # Vertex AI credentials
â”œâ”€â”€ input/                       # Input files
â”‚   â””â”€â”€ cli.js                   # Example minified JS
â”œâ”€â”€ output/                      # Output directory
â”‚   â””â”€â”€ [timestamp directories]  # Generated analysis
â”œâ”€â”€ tests/                       # Test files
â”‚   â””â”€â”€ deconstruct_pipeline.test.js # Placeholder
â”œâ”€â”€ .gitignore                   # Git ignore file
â”œâ”€â”€ package.json                 # Dependencies and scripts
â”œâ”€â”€ README.md                    # This file
â””â”€â”€ .eslintrc.json               # ESLint configuration
```

## ğŸ–¥ï¸ Usage

Run the script with a minified JavaScript file:

```bash
node src/deconstruct_pipeline.js <input_file> [--output-dir <path>] [--llm-provider <provider>] [--llm-model <model>] [--skip-llm]
```

**Examples**:

```bash
# Using Google Vertex AI (default)
node src/deconstruct_pipeline.js input/cli.js --output-dir output/custom

# Using local Ollama instance
node src/deconstruct_pipeline.js input/cli.js --llm-provider ollama --llm-model qwen3:30b-a3b-q8_0

# Using local Ollama with custom host
node src/deconstruct_pipeline.js input/cli.js --llm-provider ollama --ollama-host http://localhost:11435

# Skip LLM analysis (faster for testing)
node src/deconstruct_pipeline.js input/cli.js --skip-llm
```

**Help**:

```bash
node src/deconstruct_pipeline.js --help
```

Alternatively, use the npm script:

```bash
npm start input/cli.js --llm-provider ollama
```

## ğŸ“¥ Expected Input

Minified JavaScript files with:
- Short variable names (e.g., `zZ6`, `QZ6`, `J1`, `A`).
- No whitespace or comments.
- Compressed syntax (e.g., `import{createRequire as zZ6}from"node:module";var QZ6=Object.create;...`).

Place input files in `input/` (e.g., `input/cli.js`).

## ğŸ“¤ Output Structure

The script creates a timestamped directory (default: `output/{filename}_{timestamp}/`) with:

- `1_minified_prettier.js`: Formatted code.
- `2_minified_webcrack.js`: Deobfuscated code.
- `3_minified_tree_sitter/`: Modular files in subdirectories:
  - `functions/`: Function declarations/methods.
  - `classes/`: Class declarations.
  - `imports/`: Import statements.
  - `exports/`: Export statements.
  - `variables/`: Variable declarations.
  - `constants/`: Const/let declarations.
  - `base/`: Miscellaneous code.
- `sourcemap.json`: Maps files to original line numbers.
- `dependency_graph.json`: File relationships.
- `*_summary.md`: Per-directory summaries for each component type.
- `summaries/`: Individual category analysis files.
- `llm_analysis.md`: Comprehensive LLM analysis of all code.
- `README.md`: Output-specific documentation.
- `metadata.json`: Information about this analysis run (timestamp, model, etc.).

**Example**:

```
output/cli_2023-05-15T10-15-30-456Z/
â”œâ”€â”€ 1_minified_prettier.js
â”œâ”€â”€ 2_minified_webcrack.js
â”œâ”€â”€ 3_minified_tree_sitter/
â”‚   â”œâ”€â”€ functions/
â”‚   â”‚   â”œâ”€â”€ module_helper.js
â”‚   â”‚   â”œâ”€â”€ another_function.js
â”‚   â”œâ”€â”€ imports/
â”‚   â”‚   â”œâ”€â”€ import_createRequire.js
â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”œâ”€â”€ base.js
â”œâ”€â”€ variables_summary.md
â”œâ”€â”€ functions_summary.md
â”œâ”€â”€ arrow_functions_summary.md
â”œâ”€â”€ summaries/
â”‚   â”œâ”€â”€ structure_overview_summary.md
â”‚   â”œâ”€â”€ core_functionality_summary.md
â”‚   â”œâ”€â”€ data_structures_summary.md
â”‚   â”œâ”€â”€ module_system_summary.md
â”œâ”€â”€ sourcemap.json
â”œâ”€â”€ dependency_graph.json
â”œâ”€â”€ llm_analysis.md
â”œâ”€â”€ README.md
â”œâ”€â”€ metadata.json
```

## ğŸ§¹ Managing Output Directories

The tool creates timestamped output directories to preserve each analysis run. To manage these directories, use the cleanup utility:

```bash
# List all output directories sorted by date (newest first)
node src/utils/cleanup_outputs.js list

# List directories sorted by size
node src/utils/cleanup_outputs.js list --size

# See what directories would be removed (older than 7 days, keeping 5 newest)
node src/utils/cleanup_outputs.js cleanup

# Actually remove old directories
node src/utils/cleanup_outputs.js cleanup --force

# Customize retention settings
node src/utils/cleanup_outputs.js cleanup --days=14 --keep=3 --force
```

## ğŸ”„ Pipeline Workflow

The following Mermaid chart illustrates the pipeline's top-down workflow, showing how a minified JavaScript file is processed through each step to produce the output.

```mermaid
graph TD
    A[ğŸ“„ Input File<br>input/cli.js] -->|Minified JS| B[ğŸ–Œï¸ Prettier]
    B -->|Formatted Code| C[ğŸ” Webcrack]
    C -->|Deobfuscated Code| D[ğŸŒ³ Tree-sitter]
    D -->|Modular Files| E1[Directory Analysis]
    D --> E2[Category Analysis]
    E1 -->|Per-directory Summaries| F[ğŸ“‚ Output<br>output/{filename}_{timestamp}/]
    E2 -->|Comprehensive Analysis| F
    
    classDef pipeline fill:#4B8BBE,stroke:#333,stroke-width:2px,color:#FFF;
    class A,B,C,D,E1,E2,F pipeline;
```

**Pipeline Steps**:
1. **ğŸ–Œï¸ Prettier**: Formats minified code for readability, saving to `1_minified_prettier.js`.
2. **ğŸ” Webcrack**: Deobfuscates variable names, saving to `2_minified_webcrack.js`.
3. **ğŸŒ³ Tree-sitter**: Parses code into modular files (e.g., functions, classes), saving to `3_minified_tree_sitter/`.
4. **Directory Analysis**: Creates summaries for each component type directory using a rolling window text summarizer.
5. **Category Analysis**: Performs multi-faceted analysis of the codebase structure, functionality, data structures, and module system.
6. **ğŸ“‚ Output**: Includes directory summaries (`*_summary.md`), comprehensive analysis (`llm_analysis.md`), sourcemap, dependency graph, and metadata.

## ğŸ“ Notes

- **LLM Setup**:
  - **Vertex AI**: Obtain a service account JSON key from Google Cloud (see https://cloud.google.com/vertex-ai/docs). Ensure it has `roles/aiplatform.user` permissions.
  - **Ollama**: Install Ollama locally or use Docker. Run with `ollama serve` or use the Docker container (default port: 11434).
- **Performance**: Monitor memory usage for large files during Tree-sitter parsing.
- **Security**: Never commit `config/vertex_ai_service_account.json` or `.env`. Verify `.gitignore`.
- **Extensibility**: Add utility functions to `src/utils/` or tests to `tests/` as needed.
- **Linting**: Use ESLint (`npx eslint src/`) for code quality, configured in `.eslintrc.json`.

## ğŸ Troubleshooting

- **Module not found**:
  - Run `npm install` to install dependencies.
  - Verify `package.json` is in the root.
- **Invalid credentials**:
  - Check `config/.env` points to `config/vertex_ai_service_account.json`.
  - Ensure the JSON key is valid.
- **Output path errors**:
  - Use `--output-dir` to specify a valid path (e.g., `output/custom`).
- **Slow LLM calls**:
  - The script includes retry logic for Vertex AI rate limits. Check your quota at https://console.cloud.google.com.
- **LLM timeouts**:
  - If using Ollama and encountering timeouts, try reducing the number of files analyzed at once.

## ğŸŒ References

- Prettier: https://prettier.io/docs/en/
- Webcrack: https://github.com/j4k0xb/webcrack
- Tree-sitter: https://tree-sitter.github.io/
- LangChain.js (Vertex AI): https://js.langchain.com/docs/integrations/chat/google_vertex_ai
- Ollama: https://github.com/ollama/ollama
- Yargs: https://yargs.js.org/
- Google Vertex AI: https://cloud.google.com/vertex-ai/docs
- Node.js: https://nodejs.org/